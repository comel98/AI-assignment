# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory


import os
#print(os.listdir("../input"))

# Any results you write to the current directory are saved as output.

import pandas as pd

message = pd.read_csv(r'C:\Users\HP\Downloads\spam.csv',header=0,encoding='latin-1',usecols=[0,1],names=['labels','message'])
message.head(11)
message.describe()
message.groupby('labels').describe()
message['length']=message['message'].apply(len)
message.head()

import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

message['length'].plot(bins=50,kind='hist')
message.length.describe()
message[message['length']==910]['message'].iloc[0]

import string
mess = 'sample message!...'
nopunc=[char for char in mess if char not in string.punctuation]
nopunc=''.join(nopunc)
print(nopunc)
from nltk.corpus import stopwords
stopwords.words('english')[0:10]
nopunc.split()
clean_mess=[word for word in nopunc.split() if word.lower() not in stopwords.words('english')]
clean_mess
from nltk.stem import WordNetLemmatizer
from nltk import pos_tag, word_tokenize

lemmatizer = WordNetLemmatizer()
stopwords = set(stopwords.words('english'))
